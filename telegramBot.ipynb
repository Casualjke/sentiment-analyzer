{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346fb474-24de-4165-b344-4dc739166cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\polov\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import tqdm\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013fde3b-a01a-40b2-a64e-8fd73783e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4854b436-5525-483d-96f4-4b0d62f4451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.load_dataset(\"MonoHime/ru_sentiment_dataset\", split=[\"train\", \"validation\"]) # загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8fea860-52ce-420f-9bcf-09bfb5e06601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\polov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\polov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8871eb-928c-45ca-be5e-8df93036c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(word_tokenize) # загрузка токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb748868-bbd0-4ec0-94b3-cc773993be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, tokenizer, max_length):\n",
    "    tokens = tokenizer(example[\"text\"])[:max_length]\n",
    "    return {\"tokens\": tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f20d6d-2ec8-4e17-ad7e-1a0cabb2f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "\n",
    "train_data = train_data.map(\n",
    "    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",
    ")\n",
    "test_data = test_data.map(\n",
    "    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1eb943-92c2-42b6-a70f-52654fdbfdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25\n",
    "\n",
    "train_valid_data = train_data.train_test_split(test_size=test_size)\n",
    "train_data = train_valid_data[\"train\"]\n",
    "valid_data = train_valid_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce4c0d6-1f40-444a-ae36-1cb91d5565e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 5\n",
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1419bd66-9f1b-43e8-b537-a6892d8972af",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae7577c-4c4d-464d-8738-551f63db40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ed67fd-35d6-477d-8a4b-4c78a1218fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, vocab):\n",
    "    ids = vocab.lookup_indices(example[\"tokens\"])\n",
    "    return {\"ids\": ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f3981e-3f5e-4b2c-840c-9ceb7930a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b78fa40-1f16-405c-a79b-03026e3b19c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"sentiment\"])\n",
    "valid_data = valid_data.with_format(type=\"torch\", columns=[\"ids\", \"sentiment\"])\n",
    "test_data = test_data.with_format(type=\"torch\", columns=[\"ids\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a115271-540b-44b0-ab0b-af137998aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3c20cfb-0d75-42c6-88be-d0b140dec2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = [i[\"ids\"] for i in batch]\n",
    "        batch_ids = nn.utils.rnn.pad_sequence(\n",
    "            batch_ids, padding_value=pad_index, batch_first=True\n",
    "        )\n",
    "        batch_label = [i[\"sentiment\"] for i in batch]\n",
    "        batch_label = torch.stack(batch_label)\n",
    "        batch = {\"ids\": batch_ids, \"sentiment\": batch_label}\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "315c6e6c-d0c5-46ae-8701-b816fef0ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2f8efa1-5a8f-4f16-86e3-5c2f90cb8405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118347"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b1f88f1-2e8b-4849-b5b4-eebfaa56ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        n_filters,\n",
    "        filter_sizes,\n",
    "        output_dim,\n",
    "        dropout_rate,\n",
    "        pad_index,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(embedding_dim, n_filters, filter_size)\n",
    "                for filter_size in filter_sizes\n",
    "            ]\n",
    "        )\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, ids):\n",
    "        # ids = [batch size, seq len]\n",
    "        embedded = self.dropout(self.embedding(ids))\n",
    "        # embedded = [batch size, seq len, embedding dim]\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        # embedded = [batch size, embedding dim, seq len]\n",
    "        conved = [torch.relu(conv(embedded)) for conv in self.convs]\n",
    "        # conved_n = [batch size, n filters, seq len - filter_sizes[n] + 1]\n",
    "        pooled = [conv.max(dim=-1).values for conv in conved]\n",
    "        # pooled_n = [batch size, n filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=-1))\n",
    "        # cat = [batch size, n filters * len(filter_sizes)]\n",
    "        prediction = self.fc(cat)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd7b9ac3-75f7-4d70-bb0d-78797fa15efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "n_filters = 100\n",
    "filter_sizes = [3, 5, 7]\n",
    "output_dim = len(train_data.unique(\"sentiment\"))\n",
    "dropout_rate = 0.25\n",
    "\n",
    "model = CNN(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    n_filters,\n",
    "    filter_sizes,\n",
    "    output_dim,\n",
    "    dropout_rate,\n",
    "    pad_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aca6864-680b-446e-9ba7-ba5507eb134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, desc=\"эволюция...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            label = batch[\"sentiment\"].to(device)\n",
    "            prediction = model(ids)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e8b460b-bafe-4bd3-9e57-7057ca3c1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Conv1d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c199238b-e6d2-45b4-aed9-5fb835fc8468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(118347, 300, padding_idx=1)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(7,), stride=(1,))\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aba0cf0f-7349-4796-9012-3d960501092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.GloVe()\n",
    "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n",
    "model.embedding.weight.data = pretrained_embedding\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2d47ecb-2d55-4d08-89ef-1c694c499f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98e1873d-ae37-4ce9-b8d2-55dd3f3e5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2488c15-f958-43f4-94c8-bd936132be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16627721-feab-4ac9-9f78-43ffe9e06fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "эволюция...: 100%|█████████████████████████████████████████████████████████████████████| 42/42 [01:05<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"cnn.pt\"))\n",
    "\n",
    "test_loss, test_acc = evaluate(test_data_loader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672700d-f349-4a93-94ea-9a47b8215124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, vocab, device, min_length, pad_index):\n",
    "    tokens = tokenizer(text)\n",
    "    ids = vocab.lookup_indices(tokens)\n",
    "    if len(ids) < min_length:\n",
    "        ids += [pad_index] * (min_length - len(ids))\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_class = prediction.argmax(dim=-1).item()\n",
    "    predicted_probability = probability[predicted_class].item()\n",
    "    return predicted_class, predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38d933-d3a0-4d4a-a7c8-cee531abf279",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Обслуживание в этом ресторане оставляет желать лучшего. Официанты были невнимательными и невежливыми.\"\n",
    "min_length = max(filter_sizes)\n",
    "predict_sentiment(text, model, tokenizer, vocab, device, min_length, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdce44-b8fd-416d-b771-f2ccda9de9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "\n",
    "# Создаём экземпляр бота с API ключом\n",
    "bot = telebot.TeleBot('7081096776:AAH_eeg8cpUSdia1Vee7YYfUd3GKFF9a1Kg')\n",
    "\n",
    "# Обработчик команды /start\n",
    "@bot.message_handler(commands=['start'])\n",
    "def start(message):\n",
    "    bot.reply_to(message, 'Привет! Отправь мне текст для анализа тональности.')\n",
    "\n",
    "# Обработчик текстовых сообщений\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_text(message):\n",
    "    predicted_class, predicted_probability = predict_sentiment(message.text, model, tokenizer, vocab, device, min_length, pad_index)\n",
    "    if(predicted_class == 0): \n",
    "        sent_res = \"Нейтральная\"\n",
    "    if(predicted_class == 1):\n",
    "        sent_res = \"Позитивная\"\n",
    "    if(predicted_class == 2): \n",
    "        sent_res = \"Негативная\"\n",
    "    bot.reply_to(message, f'Тональность текста: {sent_res}, Я уверен на: {round(predicted_probability,3)}')\n",
    "\n",
    "# Запускаем бота\n",
    "bot.polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637816b0-9c34-40a6-bde3-392941e98b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
